{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOovl2HN/hcYo0eL3W5tq//"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "JCKQS9A-TRSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "aZpPZa-7TpZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(  # normalize to be between -1 and 1 so the data range is not too big\n",
        "        (0.5, 0.5, 0.5),\n",
        "        (0.5, 0.5, 0.5)\n",
        "    )\n",
        "])\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=False)\n",
        "try_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "_tDdV18rT3_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the neural network\n",
        "class ConvNeuralNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__() # mandatory line for it to initiate the network properly\n",
        "\n",
        "    #2 convolution layers\n",
        "    self.conv1 = nn.Conv2d(3, 64, 3) # takes 3 features, outputs 64 features -- 3 inputs because there are 3 values, R, G, B, 64 outputs because it learns 64 filters, last 3 is the kernel size (3x3)\n",
        "    self.conv2 = nn.Conv2d(64, 128, 3) # takes 64 features, outputs 128 features\n",
        "\n",
        "    self.pool = nn.MaxPool2d(2, stride=2) # max pooling layer with a kernel size and stride of 2, pooling layers reduce the spatial dimensions (height and width) of the feature maps, which helps for reducing the number of parameters and ensuring the model won't break to tiny changes in the data\n",
        "\n",
        "    self.fc1 = nn.Linear(128 * 6 * 6, 120) # fully connected layers\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10) # 10 output layers\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool(x)\n",
        "    x = torch.flatten(x, 1) # flatten all dimensions except for batch\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.log_softmax(self.fc3(x), dim=1)\n",
        "    return x\n",
        "\n",
        "net = ConvNeuralNet()\n",
        "net.to(device)"
      ],
      "metadata": {
        "id": "2hBoGPoxXTdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(train_loader):\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "    optimizer.zero_grad() # clear gradients\n",
        "    outputs = net(inputs) # put the images through the network\n",
        "    loss = loss_function(outputs, labels) # calculate loss\n",
        "\n",
        "    loss.backward() # calculate gradients for all the weights that need adjusting\n",
        "    optimizer.step() # optimizer run\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if i % 2000 == 1999:\n",
        "      print(f'[{epoch+1}/{epochs}, {i+1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "      running_loss = 0.0\n",
        "\n",
        "print(\"Finished training.\")"
      ],
      "metadata": {
        "id": "5EaRZTHvaxK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# method for testing it out of the training loop\n",
        "\n",
        "def view_classification(image, probabilities):\n",
        "  probabilities = probabilities.data.numpy().squeeze()\n",
        "\n",
        "  fig, (ax1, ax2) = plt.subplots(figsize=(6, 9), ncols=2)\n",
        "\n",
        "  image = image.permute(1, 2, 0)\n",
        "  denormalized_image = image / 2 + 0.5\n",
        "  ax1.imshow(denormalized_image)\n",
        "  ax1.axis('off')\n",
        "  ax2.barh(np.arange(10), probabilities)\n",
        "  ax2.set_aspect(0.1)\n",
        "  ax2.set_yticks(np.arange(10))\n",
        "  ax2.set_yticklabels(classes)\n",
        "  ax2.set_title('Class Probability')\n",
        "  ax2.set_xlim(0, 1.1)\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "hpRXQQvecHrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, _ = next(iter(try_loader))\n",
        "image_number = random.randint(0, 100)\n",
        "\n",
        "image = images[image_number]\n",
        "batched_image = image.unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    log_probabilities = net(batched_image)\n",
        "\n",
        "probabilities = torch.exp(log_probabilities).squeeze().cpu()\n",
        "view_classification(image, probabilities)"
      ],
      "metadata": {
        "id": "Gs3w3ppmdD26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test overall accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
        "# 84% accuracy, good but could be better with more layers?"
      ],
      "metadata": {
        "id": "Ev169AnZdTC9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}